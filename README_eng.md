# ğŸ™ï¸ AI Voice Chat (Whisper + Ollama)

![Python](https://img.shields.io/badge/python-3.10%2B-blue)
![PyQt6](https://img.shields.io/badge/PyQt6-GUI-green)
![Whisper](https://img.shields.io/badge/Whisper-STT-orange)
![Ollama](https://img.shields.io/badge/Ollama-LLM-purple)
![License](https://img.shields.io/badge/license-MIT-lightgrey)

A **local desktop AI voice chat** built with **Python + PyQt6**, using **Whisper** for speech-to-text and **Ollama (LLM)** for text understanding and question answering.

âœ… Works offline (after model download)
âœ… Microphone recording & audio file support
âœ… Local LLM, no cloud required

---

## ğŸš€ Features

* ğŸ§ **Microphone recording**
  Record audio directly from the app.

* ğŸ“‚ **Audio file upload**
  Supports wav / mp3 / m4a (depends on Whisper & FFmpeg).

* ğŸ“ **Speech-to-text**
  Audio is transcribed using **Whisper / faster-whisper**.

* ğŸ¤– **AI Chat (LLM)**
  Transcribed text is sent to **Ollama**, where the model:

  * answers questions;
  * explains content;
  * creates summaries.

* ğŸ–¥ï¸ **PyQt6 GUI**
  Simple desktop interface with chat and controls.

---

## ğŸ§  Tech Stack

* **Python 3.10+**
* **PyQt6** â€” GUI
* **Whisper / faster-whisper** â€” Speech-to-Text
* **Ollama** â€” Local LLM runtime
* **FFmpeg** â€” Audio processing

---

## ğŸ™ï¸ Whisper Models: Speed, Quality & Hardware

Larger Whisper models give better accuracy but require more resources.

### â±ï¸ Transcription Speed (1 minute of audio)

> Average values on **CPU (Ryzen 5 / Intel i7)** using `faster-whisper`, no GPU.

| Model      | Time per 1 min audio | Notes                    |
| ---------- | -------------------- | ------------------------ |
| **tiny**   | ~5â€“10 sec            | Near real-time           |
| **base**   | ~10â€“20 sec           | Good for notes           |
| **small**  | ~25â€“40 sec           | Best balance             |
| **medium** | ~60â€“90 sec           | High accuracy            |
| **large**  | 2â€“4 min              | Requires strong hardware |

---

### ğŸ“Œ Whisper Model Comparison

| Model      | Size    | Pros          | Cons                 | Hardware          |
| ---------- | ------- | ------------- | -------------------- | ----------------- |
| **tiny**   | ~75 MB  | Very fast     | Low accuracy         | CPU, 2 GB RAM     |
| **base**   | ~140 MB | Lightweight   | Errors on long audio | CPU, 4 GB RAM     |
| **small**  | ~460 MB | Good accuracy | Slower               | CPU/GPU, 6 GB RAM |
| **medium** | ~1.5 GB | High accuracy | Heavy                | GPU, 8â€“10 GB VRAM |
| **large**  | ~3 GB   | Best accuracy | Very heavy           | GPU, 12+ GB VRAM  |

---

## ğŸ¯ Default Presets (Recommended)

### ğŸ‘¶ Beginner (plug & play)

* **Whisper:** `small`
* **Ollama:** `mistral`
* **Mode:** CPU + faster-whisper

âœ” Good accuracy
âœ” No GPU required
âœ” Laptop-friendly

---

### âš–ï¸ Balanced

* **Whisper:** `medium`
* **Ollama:** `llama3`
* **Mode:** GPU if available

âœ” Great for lectures & interviews

---

### ğŸš€ Maximum Quality

* **Whisper:** `large`
* **Ollama:** `llama3`
* **Mode:** GPU (12â€“24 GB VRAM)

âœ” Best possible accuracy

---

## ğŸ§  CPU vs GPU: Real Differences

| Aspect         | CPU              | GPU             |
| -------------- | ---------------- | --------------- |
| Availability   | Works everywhere | NVIDIA required |
| Speed          | Slower           | 5â€“10Ã— faster    |
| Whisper models | tinyâ€“small       | mediumâ€“large    |
| Ollama         | Uses RAM         | Uses VRAM       |
| Laptops        | Ideal            | Limited         |

**Conclusion:**

* Use `faster-whisper` on CPU
* GPU is only worth it for `medium` and `large`

---

## ğŸ’» Laptops vs Desktop PCs

### ğŸ’¼ Laptop

* CPU: 4â€“8 cores
* RAM: 16 GB
* Whisper: `base` / `small`
* Ollama: `phi`, `mistral`

âš ï¸ Avoid overheating and `large` models

---

### ğŸ–¥ï¸ Desktop PC

* CPU: 8+ cores
* RAM: 32 GB
* GPU: RTX 3060+
* Whisper: `medium` / `large`
* Ollama: `llama3`

---

## ğŸ–¥ï¸ Hardware Requirements

### ğŸ’» Minimum

* CPU: 4 cores
* RAM: 8 GB
* GPU: not required
* Disk: 10 GB free

---

### âš–ï¸ Recommended

* CPU: 6â€“8 cores
* RAM: 16 GB
* GPU: optional (6â€“8 GB VRAM)
* Disk: SSD, 20â€“30 GB

---

### ğŸš€ Advanced

* CPU: 8+ cores
* RAM: 32 GB
* GPU: RTX 3060 (12 GB VRAM)
* Disk: NVMe SSD

---

## ğŸ¤– Ollama Models

| Model       | Pros                 | Cons              | RAM   |
| ----------- | -------------------- | ----------------- | ----- |
| **llama3**  | Best overall quality | Heavy             | 8+ GB |
| **mistral** | Fast & compact       | Weaker reasoning  | 6 GB  |
| **gemma**   | Lightweight          | Short answers     | 6 GB  |
| **phi**     | Very small           | Limited knowledge | 4 GB  |

---

## ğŸ“¦ Installation

```bash
git clone https://github.com/yourname/yourproject.git
cd yourproject
pip install -r requirements.txt
```

### FFmpeg

* **Windows:** download from ffmpeg.org and add to PATH
* **Linux:** `sudo apt install ffmpeg`
* **macOS:** `brew install ffmpeg`

---

## â–¶ï¸ Run

```bash
python main.py
```

---

## â— Common Issues

### Whisper crashes or fails

* Check Python 3.10+
* Make sure FFmpeg is installed
* Prefer `faster-whisper`

```bash
pip install faster-whisper
```

---

### Ollama connection refused

```bash
ollama serve
ollama list
ollama pull llama3
```

---

## ğŸ“„ License

MIT License

---

## ğŸ‘¤ Author

Your Name
GitHub: your-link
